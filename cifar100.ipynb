{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar100.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4lc9qcXlPDM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "0d14a3a8-29fb-43ac-a7fe-8d100b7412e8"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow import keras as kr\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# load dataset\n",
        "(trainX, trainY), (testX, testY) = cifar100.load_data()\n",
        "# summarize loaded dataset\n",
        "print('Train: X=%s, y=%s' % (trainX.shape, trainY.shape))\n",
        "print('Test: X=%s, y=%s' % (testX.shape, testY.shape))\n",
        "# plot first few images\n",
        "print(type(trainY))\n",
        "def filterOutArray(arrX,arrY):\n",
        "  toDelete = []\n",
        "  for i, arrIter in enumerate(arrY):\n",
        "      classIdx = arrIter.tolist()[0]\n",
        "      if (classIdx % 2 == 0):\n",
        "        toDelete.append(i)\n",
        "      else:\n",
        "          newClassIdx=(classIdx-1)/2\n",
        "          arrY[i][0]=newClassIdx\n",
        "  return np.delete(arrX, toDelete, 0),  np.delete(arrY, toDelete, 0)\n",
        "\n",
        "\n",
        "trainX, trainY=filterOutArray(trainX, trainY)\n",
        "testX, testY=filterOutArray(testX, testY)\n",
        "\n",
        "# Parse numbers as floats\n",
        "trainX = trainX.astype('float64')\n",
        "testX  = testX .astype('float64')\n",
        "\n",
        "# Scaling data to <0,1> range\n",
        "trainX =trainX / 255.0\n",
        "testX =testX / 255.0\n",
        "\n",
        "print('Train: X=%s, y=%s' % (trainX.shape, trainY.shape))\n",
        "print('Test: X=%s, y=%s' % (testX.shape, testY.shape))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 6s 0us/step\n",
            "Train: X=(50000, 32, 32, 3), y=(50000, 1)\n",
            "Test: X=(10000, 32, 32, 3), y=(10000, 1)\n",
            "<class 'numpy.ndarray'>\n",
            "Train: X=(25000, 32, 32, 3), y=(25000, 1)\n",
            "Test: X=(5000, 32, 32, 3), y=(5000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SgvAP1jyjhl"
      },
      "source": [
        "#label list for classes\n",
        "CIFAR100_LABELS_LIST = [\n",
        "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
        "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
        "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
        "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
        "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
        "    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
        "    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
        "    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
        "    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
        "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
        "    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
        "    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
        "    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
        "    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
        "    'worm'\n",
        "]\n",
        "#deliting every second label as task said\n",
        "for i  in range(50):\n",
        "  del CIFAR100_LABELS_LIST[i]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JADbarflidJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bfdf8979-fb98-4b68-8c4a-e4c86cdd24ca"
      },
      "source": [
        "\n",
        "\n",
        "import time\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "\n",
        "print('Train: X=%s, y=%s' % (trainX.shape, trainY.shape))\n",
        "print('Test: X=%s, y=%s' % (testX.shape, testY.shape))\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = models.Sequential()\n",
        "# conv2d and MaxPooling2D specialized for 2d image\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3), kernel_regularizer=kr.regularizers.l2(0.001)))\n",
        "#dropout layer to prevent overfitting\n",
        "model.add(layers.Dropout(0.2))\n",
        "\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#kernel_regularizer to prevent overfitting\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=kr.regularizers.l2(0.001)))\n",
        "\n",
        "model.add(layers.Dropout(0.2))\n",
        "\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=kr.regularizers.l2(0.001)))\n",
        "\n",
        "model.add(layers.Dropout(0.2))\n",
        "#flattening to make vector 1d for dense layer\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(500, activation='relu', kernel_regularizer=kr.regularizers.l2(0.001)))\n",
        "\n",
        "model.add(layers.Dropout(0.2))\n",
        "\n",
        "model.add(layers.Dense(50))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  0.001,\n",
        "  decay_steps=25000,\n",
        "  decay_rate=1,\n",
        "  staircase=False)\n",
        "\n",
        "\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(trainX,trainY, epochs=100,validation_data=(testX, testY))\n",
        "\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print(\"time\")\n",
        "print(end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: X=(25000, 32, 32, 3), y=(25000, 1)\n",
            "Test: X=(5000, 32, 32, 3), y=(5000, 1)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 500)               512500    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                25050     \n",
            "=================================================================\n",
            "Total params: 593,870\n",
            "Trainable params: 593,870\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 3.5245 - accuracy: 0.1313 - val_loss: 3.1884 - val_accuracy: 0.2156\n",
            "Epoch 2/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.9960 - accuracy: 0.2408 - val_loss: 3.0131 - val_accuracy: 0.2504\n",
            "Epoch 3/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.7842 - accuracy: 0.2977 - val_loss: 2.7979 - val_accuracy: 0.3180\n",
            "Epoch 4/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.6573 - accuracy: 0.3278 - val_loss: 2.8248 - val_accuracy: 0.3112\n",
            "Epoch 5/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.5665 - accuracy: 0.3552 - val_loss: 2.6559 - val_accuracy: 0.3626\n",
            "Epoch 6/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.4947 - accuracy: 0.3754 - val_loss: 2.5769 - val_accuracy: 0.3894\n",
            "Epoch 7/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.4357 - accuracy: 0.3908 - val_loss: 2.5514 - val_accuracy: 0.3870\n",
            "Epoch 8/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.3863 - accuracy: 0.4024 - val_loss: 2.5150 - val_accuracy: 0.3958\n",
            "Epoch 9/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.3402 - accuracy: 0.4138 - val_loss: 2.5689 - val_accuracy: 0.3762\n",
            "Epoch 10/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.3044 - accuracy: 0.4274 - val_loss: 2.4811 - val_accuracy: 0.4046\n",
            "Epoch 11/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.2663 - accuracy: 0.4363 - val_loss: 2.4956 - val_accuracy: 0.3952\n",
            "Epoch 12/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.2280 - accuracy: 0.4484 - val_loss: 2.3861 - val_accuracy: 0.4276\n",
            "Epoch 13/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.1996 - accuracy: 0.4586 - val_loss: 2.3758 - val_accuracy: 0.4354\n",
            "Epoch 14/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.1740 - accuracy: 0.4592 - val_loss: 2.4051 - val_accuracy: 0.4162\n",
            "Epoch 15/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.1386 - accuracy: 0.4702 - val_loss: 2.3695 - val_accuracy: 0.4390\n",
            "Epoch 16/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.1180 - accuracy: 0.4745 - val_loss: 2.3206 - val_accuracy: 0.4422\n",
            "Epoch 17/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.0867 - accuracy: 0.4841 - val_loss: 2.3045 - val_accuracy: 0.4568\n",
            "Epoch 18/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.0726 - accuracy: 0.4907 - val_loss: 2.2899 - val_accuracy: 0.4592\n",
            "Epoch 19/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.0476 - accuracy: 0.4980 - val_loss: 2.3192 - val_accuracy: 0.4432\n",
            "Epoch 20/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.0314 - accuracy: 0.5020 - val_loss: 2.2500 - val_accuracy: 0.4740\n",
            "Epoch 21/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.0048 - accuracy: 0.5094 - val_loss: 2.2911 - val_accuracy: 0.4562\n",
            "Epoch 22/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.9966 - accuracy: 0.5122 - val_loss: 2.2571 - val_accuracy: 0.4704\n",
            "Epoch 23/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.9689 - accuracy: 0.5188 - val_loss: 2.2454 - val_accuracy: 0.4662\n",
            "Epoch 24/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.9507 - accuracy: 0.5171 - val_loss: 2.3004 - val_accuracy: 0.4468\n",
            "Epoch 25/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.9349 - accuracy: 0.5302 - val_loss: 2.2714 - val_accuracy: 0.4688\n",
            "Epoch 26/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.9214 - accuracy: 0.5306 - val_loss: 2.2530 - val_accuracy: 0.4654\n",
            "Epoch 27/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.9087 - accuracy: 0.5366 - val_loss: 2.2837 - val_accuracy: 0.4636\n",
            "Epoch 28/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8932 - accuracy: 0.5408 - val_loss: 2.2095 - val_accuracy: 0.4740\n",
            "Epoch 29/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8824 - accuracy: 0.5430 - val_loss: 2.2369 - val_accuracy: 0.4750\n",
            "Epoch 30/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8611 - accuracy: 0.5497 - val_loss: 2.2153 - val_accuracy: 0.4806\n",
            "Epoch 31/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8468 - accuracy: 0.5540 - val_loss: 2.2088 - val_accuracy: 0.4828\n",
            "Epoch 32/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8369 - accuracy: 0.5565 - val_loss: 2.2227 - val_accuracy: 0.4784\n",
            "Epoch 33/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8253 - accuracy: 0.5570 - val_loss: 2.2000 - val_accuracy: 0.4854\n",
            "Epoch 34/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8119 - accuracy: 0.5591 - val_loss: 2.2025 - val_accuracy: 0.4856\n",
            "Epoch 35/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8026 - accuracy: 0.5632 - val_loss: 2.2683 - val_accuracy: 0.4594\n",
            "Epoch 36/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7912 - accuracy: 0.5660 - val_loss: 2.2062 - val_accuracy: 0.4812\n",
            "Epoch 37/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7773 - accuracy: 0.5693 - val_loss: 2.1790 - val_accuracy: 0.4906\n",
            "Epoch 38/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7579 - accuracy: 0.5764 - val_loss: 2.2086 - val_accuracy: 0.4844\n",
            "Epoch 39/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7568 - accuracy: 0.5736 - val_loss: 2.1620 - val_accuracy: 0.4972\n",
            "Epoch 40/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7462 - accuracy: 0.5786 - val_loss: 2.1996 - val_accuracy: 0.4820\n",
            "Epoch 41/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7395 - accuracy: 0.5802 - val_loss: 2.1975 - val_accuracy: 0.4868\n",
            "Epoch 42/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7279 - accuracy: 0.5815 - val_loss: 2.1867 - val_accuracy: 0.4874\n",
            "Epoch 43/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7188 - accuracy: 0.5919 - val_loss: 2.2077 - val_accuracy: 0.4870\n",
            "Epoch 44/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7106 - accuracy: 0.5902 - val_loss: 2.2092 - val_accuracy: 0.4790\n",
            "Epoch 45/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6941 - accuracy: 0.5926 - val_loss: 2.1622 - val_accuracy: 0.4978\n",
            "Epoch 46/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6819 - accuracy: 0.5959 - val_loss: 2.1872 - val_accuracy: 0.4884\n",
            "Epoch 47/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6770 - accuracy: 0.5999 - val_loss: 2.2161 - val_accuracy: 0.4804\n",
            "Epoch 48/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6685 - accuracy: 0.5990 - val_loss: 2.1795 - val_accuracy: 0.4902\n",
            "Epoch 49/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6590 - accuracy: 0.6039 - val_loss: 2.1815 - val_accuracy: 0.4908\n",
            "Epoch 50/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6540 - accuracy: 0.6030 - val_loss: 2.2275 - val_accuracy: 0.4740\n",
            "Epoch 51/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6483 - accuracy: 0.6054 - val_loss: 2.1980 - val_accuracy: 0.4796\n",
            "Epoch 52/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6388 - accuracy: 0.6058 - val_loss: 2.1885 - val_accuracy: 0.4840\n",
            "Epoch 53/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6137 - accuracy: 0.6153 - val_loss: 2.1924 - val_accuracy: 0.4934\n",
            "Epoch 54/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6302 - accuracy: 0.6139 - val_loss: 2.1898 - val_accuracy: 0.4932\n",
            "Epoch 55/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6123 - accuracy: 0.6152 - val_loss: 2.1958 - val_accuracy: 0.4868\n",
            "Epoch 56/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.5980 - accuracy: 0.6209 - val_loss: 2.1906 - val_accuracy: 0.4884\n",
            "Epoch 57/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.6066 - accuracy: 0.6174 - val_loss: 2.1837 - val_accuracy: 0.4900\n",
            "Epoch 58/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.5868 - accuracy: 0.6207 - val_loss: 2.1527 - val_accuracy: 0.4972\n",
            "Epoch 59/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.5968 - accuracy: 0.6214 - val_loss: 2.1942 - val_accuracy: 0.4960\n",
            "Epoch 60/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.5841 - accuracy: 0.6215 - val_loss: 2.2064 - val_accuracy: 0.4848\n",
            "Epoch 61/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.5786 - accuracy: 0.6228 - val_loss: 2.1610 - val_accuracy: 0.4888\n",
            "Epoch 62/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.5697 - accuracy: 0.6265 - val_loss: 2.1912 - val_accuracy: 0.4894\n",
            "Epoch 63/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.5748 - accuracy: 0.6290 - val_loss: 2.1983 - val_accuracy: 0.4806\n",
            "Epoch 64/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.5597 - accuracy: 0.6286 - val_loss: 2.2110 - val_accuracy: 0.4764\n",
            "Epoch 65/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.5458 - accuracy: 0.6294 - val_loss: 2.1863 - val_accuracy: 0.4878\n",
            "Epoch 66/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.5405 - accuracy: 0.6358 - val_loss: 2.1983 - val_accuracy: 0.4878\n",
            "Epoch 67/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.5350 - accuracy: 0.6358 - val_loss: 2.1838 - val_accuracy: 0.4892\n",
            "Epoch 68/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.5285 - accuracy: 0.6388 - val_loss: 2.1829 - val_accuracy: 0.4894\n",
            "Epoch 69/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.5355 - accuracy: 0.6334 - val_loss: 2.1622 - val_accuracy: 0.4962\n",
            "Epoch 70/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.5175 - accuracy: 0.6407 - val_loss: 2.1401 - val_accuracy: 0.4962\n",
            "Epoch 71/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.5201 - accuracy: 0.6399 - val_loss: 2.1288 - val_accuracy: 0.5004\n",
            "Epoch 72/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.5152 - accuracy: 0.6402 - val_loss: 2.1860 - val_accuracy: 0.4878\n",
            "Epoch 73/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4942 - accuracy: 0.6464 - val_loss: 2.1636 - val_accuracy: 0.4972\n",
            "Epoch 74/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4851 - accuracy: 0.6498 - val_loss: 2.1591 - val_accuracy: 0.4894\n",
            "Epoch 75/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.5015 - accuracy: 0.6442 - val_loss: 2.1587 - val_accuracy: 0.4946\n",
            "Epoch 76/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4928 - accuracy: 0.6438 - val_loss: 2.2004 - val_accuracy: 0.4870\n",
            "Epoch 77/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4878 - accuracy: 0.6456 - val_loss: 2.1296 - val_accuracy: 0.5012\n",
            "Epoch 78/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4794 - accuracy: 0.6479 - val_loss: 2.1175 - val_accuracy: 0.5068\n",
            "Epoch 79/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4755 - accuracy: 0.6501 - val_loss: 2.1225 - val_accuracy: 0.5120\n",
            "Epoch 80/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4610 - accuracy: 0.6550 - val_loss: 2.1403 - val_accuracy: 0.5028\n",
            "Epoch 81/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4686 - accuracy: 0.6539 - val_loss: 2.1598 - val_accuracy: 0.4954\n",
            "Epoch 82/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4725 - accuracy: 0.6521 - val_loss: 2.1420 - val_accuracy: 0.4982\n",
            "Epoch 83/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4595 - accuracy: 0.6552 - val_loss: 2.1584 - val_accuracy: 0.4948\n",
            "Epoch 84/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4494 - accuracy: 0.6595 - val_loss: 2.1594 - val_accuracy: 0.4936\n",
            "Epoch 85/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4531 - accuracy: 0.6593 - val_loss: 2.1656 - val_accuracy: 0.4940\n",
            "Epoch 86/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4386 - accuracy: 0.6612 - val_loss: 2.1816 - val_accuracy: 0.4832\n",
            "Epoch 87/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4445 - accuracy: 0.6593 - val_loss: 2.1556 - val_accuracy: 0.4996\n",
            "Epoch 88/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4455 - accuracy: 0.6601 - val_loss: 2.1087 - val_accuracy: 0.5064\n",
            "Epoch 89/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4400 - accuracy: 0.6595 - val_loss: 2.1594 - val_accuracy: 0.4970\n",
            "Epoch 90/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4345 - accuracy: 0.6593 - val_loss: 2.1277 - val_accuracy: 0.5012\n",
            "Epoch 91/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4266 - accuracy: 0.6633 - val_loss: 2.1211 - val_accuracy: 0.5046\n",
            "Epoch 92/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4094 - accuracy: 0.6693 - val_loss: 2.1492 - val_accuracy: 0.5004\n",
            "Epoch 93/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4135 - accuracy: 0.6665 - val_loss: 2.1553 - val_accuracy: 0.4858\n",
            "Epoch 94/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4145 - accuracy: 0.6677 - val_loss: 2.1722 - val_accuracy: 0.4902\n",
            "Epoch 95/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4103 - accuracy: 0.6703 - val_loss: 2.1471 - val_accuracy: 0.4952\n",
            "Epoch 96/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4083 - accuracy: 0.6715 - val_loss: 2.1442 - val_accuracy: 0.5014\n",
            "Epoch 97/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4040 - accuracy: 0.6702 - val_loss: 2.1671 - val_accuracy: 0.4940\n",
            "Epoch 98/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.4003 - accuracy: 0.6711 - val_loss: 2.1477 - val_accuracy: 0.4934\n",
            "Epoch 99/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.3975 - accuracy: 0.6690 - val_loss: 2.1986 - val_accuracy: 0.4868\n",
            "Epoch 100/100\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.3942 - accuracy: 0.6705 - val_loss: 2.1373 - val_accuracy: 0.5074\n",
            "time\n",
            "325.2653257846832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n7rogSC3zZ5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "d4cdbea4-1c1d-4845-a7d9-79c48c327f44"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(testX,  testY, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 - 0s - loss: 2.1373 - accuracy: 0.5074\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO7kc0K5fdpr"
      },
      "source": [
        "Największym problemem w treningu byo nadmierne dopasowanie co można wyczytać z wykresu. Aby mu zapobiec zastosowałem DropoutLayer aby losowe neurony były zerowane,  kernel_regularizer aby wagi nie miały dużych wartosci i nie dostosowywały się zbytnio do danych treningowych. Niestety nie udało się "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArX70JtBxA9V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6bf9e74f-80d2-4ef0-b604-d2a6d563fb72"
      },
      "source": [
        "# generting confusion matrix with labels\n",
        "predictionY = np.argmax(model.predict(testX), axis=-1)\n",
        "trueY=testY.ravel()\n",
        "predictionY\n",
        "\n",
        "import pandas as pd\n",
        "np.set_printoptions(threshold=10000)\n",
        "print(trueY.shape)\n",
        "print(predictionY.shape)\n",
        "data = {'y_Actual':    trueY,\n",
        "        'y_Predicted': predictionY\n",
        "        \n",
        "        }\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
        "confusion_matrix.columns=CIFAR100_LABELS_LIST\n",
        "confusion_matrix.insert(0, \"names\",CIFAR100_LABELS_LIST, True) \n",
        "confusion_matrix.set_index(\"names\")\n",
        "\n",
        "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  \n",
        "    print (confusion_matrix)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000,)\n",
            "(5000,)\n",
            "                names  aquarium_fish  bear  bed  beetle  bottle  boy  bus  \\\n",
            "Actual                                                                      \n",
            "0       aquarium_fish             65     1    0       0       0    0    1   \n",
            "1                bear              0    22    0       0       1    0    0   \n",
            "2                 bed              1     0   43       0       1    1    1   \n",
            "3              beetle              1     1    0      43       1    0    0   \n",
            "4              bottle              0     0    0       0      60    0    0   \n",
            "5                 boy              1     2    3       0       1   27    2   \n",
            "6                 bus              0     0    2       0       0    0   41   \n",
            "7               camel              0     0    1       0       1    0    0   \n",
            "8              castle              0     0    1       0       0    0    0   \n",
            "9              cattle              0     2    1       0       1    0    0   \n",
            "10         chimpanzee              0     7    0       0       0    0    0   \n",
            "11              cloud              0     0    0       0       0    0    0   \n",
            "12              couch              2     0    9       1       0    1    1   \n",
            "13          crocodile              0     1    0       0       0    0    0   \n",
            "14           dinosaur              1     2    1       0       1    1    0   \n",
            "15           elephant              0     0    0       0       0    0    0   \n",
            "16             forest              0     0    1       0       1    0    0   \n",
            "17               girl              0     3    2       0       0    8    1   \n",
            "18              house              0     1    0       0       0    0    2   \n",
            "19           keyboard              0     0    2       0       2    0    1   \n",
            "20         lawn_mower              3     0    0       0       0    1    3   \n",
            "21               lion              1     1    2       0       0    0    0   \n",
            "22            lobster              2     0    3       0       1    1    1   \n",
            "23         maple_tree              1     0    0       0       0    0    0   \n",
            "24           mountain              2     0    0       0       1    0    0   \n",
            "25           mushroom              3     2    0       0       0    0    0   \n",
            "26             orange              2     0    0       1       1    0    1   \n",
            "27              otter              0     5    0       0       0    0    1   \n",
            "28               pear              0     1    1       1       5    1    0   \n",
            "29          pine_tree              0     0    0       0       0    0    0   \n",
            "30              plate              2     1    0       0       1    1    1   \n",
            "31          porcupine              0     1    0       0       0    0    0   \n",
            "32             rabbit              1     2    1       0       0    0    0   \n",
            "33                ray              0     0    0       0       0    0    0   \n",
            "34             rocket              0     0    0       0       3    0    0   \n",
            "35                sea              0     0    0       0       0    0    0   \n",
            "36              shark              1     1    0       0       0    0    0   \n",
            "37              skunk              0     3    0       1       0    0    0   \n",
            "38              snail              3     0    2       0       0    0    0   \n",
            "39             spider              0     0    2       2       0    1    0   \n",
            "40          streetcar              0     1    2       0       0    0    7   \n",
            "41       sweet_pepper              3     0    0       1       4    2    1   \n",
            "42               tank              1     1    0       0       0    0    1   \n",
            "43         television              2     3    6       0       1    0    2   \n",
            "44            tractor              1     0    0       0       0    1    2   \n",
            "45              trout              3     0    5       0       0    0    0   \n",
            "46             turtle              0     1    1       1       0    0    0   \n",
            "47              whale              1     1    1       1       0    0    0   \n",
            "48               wolf              0     1    0       1       0    0    0   \n",
            "49               worm              0     0    3       1       0    0    0   \n",
            "\n",
            "        camel  castle  cattle  chimpanzee  cloud  couch  crocodile  dinosaur  \\\n",
            "Actual                                                                         \n",
            "0           0       0       0           0      0      0          2         1   \n",
            "1           2       0       2          12      3      2          3         2   \n",
            "2           0       0       0           0      3     14          2         0   \n",
            "3           1       0       2           0      1      0          4         1   \n",
            "4           1       1       1           1      1      0          0         0   \n",
            "5           0       1       0           7      0      1          2         0   \n",
            "6           0       3       0           0      0      6          0         0   \n",
            "7          38       2       3           1      0      1          6         3   \n",
            "8           2      70       0           0      1      0          0         0   \n",
            "9           7       3      22           2      0      1          5         0   \n",
            "10          0       0       1          70      0      0          1         0   \n",
            "11          0       0       0           1     85      0          0         0   \n",
            "12          0       2       0           0      6     43          3         0   \n",
            "13          0       0       0           0      1      1         60         0   \n",
            "14          1       0       2           1      1      0          5        38   \n",
            "15          2       2       2           2      1      0          2         2   \n",
            "16          0       6       0           0      0      1          6         0   \n",
            "17          2       0       1           6      1      1          2         1   \n",
            "18          3      12       2           0      2      5          0         0   \n",
            "19          0       0       0           0      7      0          3         0   \n",
            "20          1       0       0           3      0      0          1         0   \n",
            "21          0       1       1           2      0      2          3         0   \n",
            "22          1       0       0           0      1      0         10         1   \n",
            "23          0       0       0           2      0      0          0         1   \n",
            "24          0       1       0           0      9      1          0         0   \n",
            "25          1       0       1           1      0      0          5         0   \n",
            "26          0       1       0           0      0      0          1         0   \n",
            "27          0       1       1           2      3      1         11         2   \n",
            "28          2       0       0           0      1      1          3         0   \n",
            "29          0       2       1           0      1      0          2         0   \n",
            "30          0       0       0           0      1      2          3         0   \n",
            "31          0       0       0           5      0      1          4         0   \n",
            "32          0       0       1           3      1      2          5         0   \n",
            "33          1       0       0           0      7      1          8         1   \n",
            "34          0       1       0           0      4      0          1         0   \n",
            "35          0       0       0           0     13      1          0         0   \n",
            "36          1       0       0           0      1      0          8         0   \n",
            "37          0       0       1           0      0      0          4         0   \n",
            "38          0       0       3           1      0      1         10         0   \n",
            "39          0       0       0           1      0      0          5         0   \n",
            "40          0       3       1           0      0      1          0         0   \n",
            "41          0       0       0           0      0      4          0         2   \n",
            "42          0       2       1           1      0      1          7         0   \n",
            "43          0       0       0           0      1      3          0         0   \n",
            "44          0       2       2           0      0      1          4         0   \n",
            "45          0       0       0           0      1      1         15         0   \n",
            "46          1       0       0           1      0      0         10         1   \n",
            "47          0       0       0           2      1      0          1         0   \n",
            "48          0       1       0           2      0      0          7         1   \n",
            "49          0       0       1           1      1      3          2         0   \n",
            "\n",
            "        elephant  forest  girl  house  keyboard  lawn_mower  lion  lobster  \\\n",
            "Actual                                                                       \n",
            "0              0       3     0      0         0           1     0        0   \n",
            "1             16       1     0      0         0           0     1        0   \n",
            "2              1       2     2      3         1           0     2        1   \n",
            "3              0       2     0      0         0           2     0        3   \n",
            "4              1       2     3      0         0           0     0        1   \n",
            "5              1       0    20      1         0           0     1        2   \n",
            "6              0       2     0     12         0           2     1        0   \n",
            "7             10       0     1      4         0           0     6        0   \n",
            "8              1       3     0      8         0           0     0        0   \n",
            "9             18       0     0      1         0           1     2        2   \n",
            "10             3       0     0      0         0           0     0        0   \n",
            "11             1       0     0      0         0           0     0        0   \n",
            "12             0       3     0      1         2           0     0        0   \n",
            "13             1       7     0      1         0           0     1        1   \n",
            "14            10       2     0      2         0           1     2        2   \n",
            "15            56       1     1      0         0           0     2        0   \n",
            "16             4      56     0      0         1           0     0        2   \n",
            "17             1       0    39      0         1           0     2        3   \n",
            "18             4       1     0     43         0           0     0        1   \n",
            "19             2       6     0      1        54           0     1        1   \n",
            "20             0       2     0      1         0          55     0        3   \n",
            "21             0       1     2      0         0           0    57        0   \n",
            "22             2       4     0      1         1           1     3       36   \n",
            "23             0       3     0      0         0           0     0        0   \n",
            "24             1       1     0      1         2           0     0        0   \n",
            "25             5       8     1      2         0           0     5        1   \n",
            "26             0       0     1      0         0           0     1        3   \n",
            "27             4       3     0      0         0           0     0        1   \n",
            "28             2       2     1      1         1           0     0        1   \n",
            "29             1       4     0      2         0           0     0        0   \n",
            "30             0       0     1      0         1           0     2        1   \n",
            "31             5       2     0      0         0           0     1        0   \n",
            "32             4       1     1      0         2           0     2        0   \n",
            "33             1       1     0      0         0           0     0        2   \n",
            "34             2       0     0      0         0           0     0        0   \n",
            "35             1       0     0      0         1           0     0        0   \n",
            "36             0       0     0      0         0           0     0        0   \n",
            "37             3       0     0      2         0           1     0        1   \n",
            "38             2       0     1      0         0           0     5        0   \n",
            "39             1       3     0      1         1           0     0        0   \n",
            "40             1       5     0      7         1           0     0        0   \n",
            "41             0       3     0      0         0           1     1       10   \n",
            "42             1       2     0      2         0           0     0        0   \n",
            "43             0       2     2      1         1           0     0        0   \n",
            "44             1       2     0      4         0           1     1        2   \n",
            "45             1       0     0      0         0           0     1        0   \n",
            "46             2       0     1      1         2           0     0        1   \n",
            "47             0       0     0      0         1           0     0        0   \n",
            "48             3       3     0      0         0           0     1        0   \n",
            "49             1       1     1      0         3           0     1        1   \n",
            "\n",
            "        maple_tree  mountain  mushroom  orange  otter  pear  pine_tree  plate  \\\n",
            "Actual                                                                          \n",
            "0                0         0         5       3      1     1          0      1   \n",
            "1                0         0         1       0      6     0          1      1   \n",
            "2                0         0         0       0      0     0          0      0   \n",
            "3                0         0         1       0      2     1          1      1   \n",
            "4                0         1         0       0      0     0          1      1   \n",
            "5                0         1         2       0      3     0          1      2   \n",
            "6                0         0         0       0      0     0          3      0   \n",
            "7                0         1         0       1      3     1          1      0   \n",
            "8                0         6         0       0      0     0          0      0   \n",
            "9                0         0         2       0      2     0          0      0   \n",
            "10               0         0         0       0      3     0          0      0   \n",
            "11               0         2         0       0      0     0          0      0   \n",
            "12               0         1         0       1      2     0          0      1   \n",
            "13               0         0         0       0      4     0          0      0   \n",
            "14               2         0         0       0      2     0          1      0   \n",
            "15               0         0         1       0      3     0          0      0   \n",
            "16               3         1         0       1      1     0          3      0   \n",
            "17               0         0         0       0      2     0          0      2   \n",
            "18               0         3         1       0      1     0          0      0   \n",
            "19               0         1         0       0      0     1          0      1   \n",
            "20               0         0         1       0      1     1          1      1   \n",
            "21               0         0         1       2      4     0          0      2   \n",
            "22               3         1         0       1      2     1          0      1   \n",
            "23              72         1         0       1      0     0         13      0   \n",
            "24               0        53         0       0      0     0          3      0   \n",
            "25               0         0        40       0      2     1          0      0   \n",
            "26               0         0         0      74      0     8          0      1   \n",
            "27               0         0         1       0     22     0          1      0   \n",
            "28               0         0         2       2      2    46          0      0   \n",
            "29               9         2         1       0      0     0         55      0   \n",
            "30               0         0         0       1      0     0          0     62   \n",
            "31               0         0         1       0      3     0          0      0   \n",
            "32               0         0         1       0      7     0          0      4   \n",
            "33               0         0         0       0      4     1          0      2   \n",
            "34               0         0         0       0      0     0          0      0   \n",
            "35               0         2         0       0      0     0          0      0   \n",
            "36               0         1         0       0      1     0          0      0   \n",
            "37               1         0         0       0      3     0          0      0   \n",
            "38               1         0         2       0      6     1          1      1   \n",
            "39               0         0         0       0      3     0          1      0   \n",
            "40               0         0         0       0      2     0          1      0   \n",
            "41               0         0         1      16      0    13          2      2   \n",
            "42               1         3         0       0      0     1          1      0   \n",
            "43               0         1         0       0      1     0          0      0   \n",
            "44               0         0         1       0      2     0          3      0   \n",
            "45               0         0         0       0      0     1          0      3   \n",
            "46               0         1         0       0      3     0          0      1   \n",
            "47               0         0         0       0      3     0          0      0   \n",
            "48               0         0         1       0      1     0          1      0   \n",
            "49               0         1         1       0      3     1          0      8   \n",
            "\n",
            "        porcupine  rabbit  ray  rocket  sea  shark  skunk  snail  spider  \\\n",
            "Actual                                                                     \n",
            "0               0       2    2       0    0      2      0      1       0   \n",
            "1               9       2    1       0    0      0      0      1       0   \n",
            "2               0       3    1       0    4      0      0      0       1   \n",
            "3               3       2    1       0    0      0      0      4       7   \n",
            "4               0       3    2       6    0      2      1      0       2   \n",
            "5               2       0    0       1    0      0      0      2       3   \n",
            "6               2       0    1       0    1      0      0      0       0   \n",
            "7               1       3    2       0    0      0      0      0       1   \n",
            "8               0       1    1       1    0      0      0      0       0   \n",
            "9               6       4    0       1    1      0      2      0       2   \n",
            "10              4       2    2       0    0      1      0      0       0   \n",
            "11              1       0    0       1    8      0      0      0       0   \n",
            "12              0       1    2       1    3      0      0      0       0   \n",
            "13              2       2    3       0    0      1      1      0       1   \n",
            "14              5       0    0       1    1      0      0      0       5   \n",
            "15             10       2    0       0    0      0      2      0       2   \n",
            "16              0       4    2       0    2      0      0      1       1   \n",
            "17              2       1    0       0    0      0      1      2       2   \n",
            "18              1       1    0       0    1      0      0      0       0   \n",
            "19              1       1    2       0    2      0      0      0       2   \n",
            "20              2       1    0       0    0      0      0      0       1   \n",
            "21              5       1    0       0    0      0      0      2       3   \n",
            "22              2       1    2       0    0      0      0      1       2   \n",
            "23              1       0    0       0    0      0      0      1       1   \n",
            "24              0       1    3       1   14      1      0      0       1   \n",
            "25              6       1    1       1    0      1      0      3       3   \n",
            "26              0       0    0       0    0      0      0      0       0   \n",
            "27              7       2    5       2    0      2      0      5       2   \n",
            "28              0       3    2       0    0      0      0      5       3   \n",
            "29              2       0    4       0    0      0      0      0       3   \n",
            "30              4       0    4       0    0      0      1      0       0   \n",
            "31             59       5    3       0    1      0      0      2       0   \n",
            "32              4      40    2       0    0      1      0      0       4   \n",
            "33              4       2   46       0    0      8      0      2       1   \n",
            "34              0       0    3      73    2      0      1      0       5   \n",
            "35              0       0    1       0   77      0      0      0       0   \n",
            "36              0       1   21       3    1     42      1      0       0   \n",
            "37              0       2    0       2    0      0     67      0       1   \n",
            "38              5       5    4       0    0      0      0     27       7   \n",
            "39              0       3    3       2    0      0      0      1      62   \n",
            "40              0       0    0       0    1      0      0      0       0   \n",
            "41              0       0    0       0    1      0      0      1       0   \n",
            "42              1       0    1       3    1      1      0      1       0   \n",
            "43              0       2    0       1    0      0      1      0       0   \n",
            "44              1       2    0       0    0      0      0      0       2   \n",
            "45              0       0    3       0    2      3      1      0       0   \n",
            "46              8       3   10       2    0     10      1      1       3   \n",
            "47              1       1    3       2    1     14      1      0       0   \n",
            "48              5       4    2       0    0      1      0      0       2   \n",
            "49              2       3    4       2    1      4      1      0       2   \n",
            "\n",
            "        streetcar  sweet_pepper  tank  television  tractor  trout  turtle  \\\n",
            "Actual                                                                      \n",
            "0               1             0     0           0        2      2       3   \n",
            "1               1             0     1           0        1      0       1   \n",
            "2               4             0     2           3        0      1       0   \n",
            "3               0             3     1           0        1      0       2   \n",
            "4               1             0     1           1        3      1       0   \n",
            "5               2             0     0           2        0      1       0   \n",
            "6              15             0     3           3        2      0       0   \n",
            "7               0             0     0           0        1      0       2   \n",
            "8               0             0     0           0        0      0       2   \n",
            "9               0             0     2           0        3      1       0   \n",
            "10              0             0     1           0        0      0       0   \n",
            "11              0             0     0           0        0      1       0   \n",
            "12              3             1     0           7        1      0       0   \n",
            "13              0             0     0           0        0      2       2   \n",
            "14              2             0     2           0        0      1       3   \n",
            "15              1             0     1           1        2      0       1   \n",
            "16              0             0     0           0        1      0       0   \n",
            "17              0             1     0           1        1      1       0   \n",
            "18              7             0     3           1        3      0       0   \n",
            "19              0             0     2           0        0      0       0   \n",
            "20              4             1     1           3        8      0       0   \n",
            "21              0             0     0           0        1      0       0   \n",
            "22              1             0     2           0        3      0       2   \n",
            "23              0             0     1           0        1      0       1   \n",
            "24              1             0     0           0        0      0       0   \n",
            "25              0             0     0           0        1      2       1   \n",
            "26              0             1     0           0        1      1       0   \n",
            "27              0             0     0           2        0      2       2   \n",
            "28              0             3     0           2        3      0       2   \n",
            "29              1             0     5           0        0      0       2   \n",
            "30              0             0     1           2        0      2       3   \n",
            "31              0             0     0           0        0      1       2   \n",
            "32              0             0     1           1        0      0       1   \n",
            "33              0             0     0           0        0      0       3   \n",
            "34              0             0     0           0        1      0       0   \n",
            "35              0             0     0           1        0      0       0   \n",
            "36              0             0     1           0        0      3       1   \n",
            "37              0             0     0           0        1      2       0   \n",
            "38              0             0     0           0        0      1       3   \n",
            "39              0             0     0           0        0      0       1   \n",
            "40             62             0     1           0        3      0       1   \n",
            "41              0            26     1           0        0      0       1   \n",
            "42              5             0    53           0        4      2       1   \n",
            "43              0             0     2          66        2      0       0   \n",
            "44              3             0     5           1       54      0       1   \n",
            "45              2             0     2           0        0     52       0   \n",
            "46              0             0     1           1        0      3      26   \n",
            "47              0             0     0           0        0      2       3   \n",
            "48              1             0     1           1        0      1       0   \n",
            "49              1             0     0           1        0      0       0   \n",
            "\n",
            "        whale  wolf  worm  \n",
            "Actual                     \n",
            "0           0     0     0  \n",
            "1           0     7     0  \n",
            "2           0     0     3  \n",
            "3           2     4     2  \n",
            "4           0     0     2  \n",
            "5           0     4     2  \n",
            "6           0     1     0  \n",
            "7           1     5     0  \n",
            "8           0     3     0  \n",
            "9           0     4     2  \n",
            "10          0     5     0  \n",
            "11          0     0     0  \n",
            "12          1     1     0  \n",
            "13          4     2     2  \n",
            "14          1     1     0  \n",
            "15          0     1     0  \n",
            "16          0     1     1  \n",
            "17          0     6     4  \n",
            "18          0     1     1  \n",
            "19          3     2     2  \n",
            "20          0     0     1  \n",
            "21          0     5     1  \n",
            "22          2     2     2  \n",
            "23          0     0     0  \n",
            "24          3     0     0  \n",
            "25          0     2     0  \n",
            "26          0     0     2  \n",
            "27          4     6     0  \n",
            "28          0     0     1  \n",
            "29          2     1     0  \n",
            "30          0     0     3  \n",
            "31          0     4     0  \n",
            "32          2     4     2  \n",
            "33          3     0     2  \n",
            "34          3     0     1  \n",
            "35          3     0     0  \n",
            "36          9     0     3  \n",
            "37          4     0     1  \n",
            "38          1     4     3  \n",
            "39          0     4     3  \n",
            "40          0     0     0  \n",
            "41          0     0     4  \n",
            "42          0     1     0  \n",
            "43          0     0     0  \n",
            "44          0     1     0  \n",
            "45          1     2     1  \n",
            "46          2     1     0  \n",
            "47         58     1     1  \n",
            "48          0    58     1  \n",
            "49          1     2    42  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCpiHKdalvyG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc4608bf-3192-4654-a3df-6542b614ffb8"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(trueY,predictionY,target_names=CIFAR100_LABELS_LIST))\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "aquarium_fish       0.63      0.65      0.64       100\n",
            "         bear       0.33      0.22      0.26       100\n",
            "          bed       0.45      0.43      0.44       100\n",
            "       beetle       0.80      0.43      0.56       100\n",
            "       bottle       0.69      0.60      0.64       100\n",
            "          boy       0.59      0.27      0.37       100\n",
            "          bus       0.59      0.41      0.48       100\n",
            "        camel       0.57      0.38      0.46       100\n",
            "       castle       0.60      0.70      0.65       100\n",
            "       cattle       0.42      0.22      0.29       100\n",
            "   chimpanzee       0.54      0.70      0.61       100\n",
            "        cloud       0.53      0.85      0.66       100\n",
            "        couch       0.42      0.43      0.42       100\n",
            "    crocodile       0.25      0.60      0.36       100\n",
            "     dinosaur       0.67      0.38      0.48       100\n",
            "     elephant       0.32      0.56      0.41       100\n",
            "       forest       0.39      0.56      0.46       100\n",
            "         girl       0.50      0.39      0.44       100\n",
            "        house       0.42      0.43      0.42       100\n",
            "     keyboard       0.71      0.54      0.61       100\n",
            "   lawn_mower       0.83      0.55      0.66       100\n",
            "         lion       0.56      0.57      0.56       100\n",
            "      lobster       0.44      0.36      0.40       100\n",
            "   maple_tree       0.78      0.72      0.75       100\n",
            "     mountain       0.64      0.53      0.58       100\n",
            "     mushroom       0.60      0.40      0.48       100\n",
            "       orange       0.72      0.74      0.73       100\n",
            "        otter       0.20      0.22      0.21       100\n",
            "         pear       0.58      0.46      0.51       100\n",
            "    pine_tree       0.58      0.55      0.56       100\n",
            "        plate       0.63      0.62      0.63       100\n",
            "    porcupine       0.35      0.59      0.44       100\n",
            "       rabbit       0.34      0.40      0.37       100\n",
            "          ray       0.31      0.46      0.37       100\n",
            "       rocket       0.69      0.73      0.71       100\n",
            "          sea       0.62      0.77      0.68       100\n",
            "        shark       0.45      0.42      0.43       100\n",
            "        skunk       0.82      0.67      0.74       100\n",
            "        snail       0.43      0.27      0.33       100\n",
            "       spider       0.45      0.62      0.52       100\n",
            "    streetcar       0.53      0.62      0.57       100\n",
            " sweet_pepper       0.72      0.26      0.38       100\n",
            "         tank       0.55      0.53      0.54       100\n",
            "   television       0.66      0.66      0.66       100\n",
            "      tractor       0.52      0.54      0.53       100\n",
            "        trout       0.61      0.52      0.56       100\n",
            "       turtle       0.36      0.26      0.30       100\n",
            "        whale       0.53      0.58      0.55       100\n",
            "         wolf       0.40      0.58      0.47       100\n",
            "         worm       0.44      0.42      0.43       100\n",
            "\n",
            "     accuracy                           0.51      5000\n",
            "    macro avg       0.53      0.51      0.51      5000\n",
            " weighted avg       0.53      0.51      0.51      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2dkmJVCGUia",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f0ced628-cf67-478a-c68f-adda37d56153"
      },
      "source": [
        "\n",
        "model.save('model.h5')\n",
        "from google.colab import files\n",
        "files.download(\"model.h5\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7e214515-6249-4440-9648-c7f5161d704c\", \"model.h5\", 7182272)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}